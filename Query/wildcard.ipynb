{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wildcard Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import *\n",
    "from nltk.stem.porter import *\n",
    "import pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing PorterStemmer Object for normalization of query terms and getting the stop_words corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming porter object\n",
    "stemmer = PorterStemmer()\n",
    "root = Path(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the inverted_index, transformed documents and file name binary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = root / \"Pickled_files\" / \"Inverted_index\"\n",
    "dbfile = open(my_path, 'rb')     \n",
    "inverted_idx = pickle.load(dbfile)\n",
    "dbfile.close()\n",
    "\n",
    "my_path = root / \"Pickled_files\" / \"Documents\"\n",
    "dbfile = open(my_path, 'rb')     \n",
    "docs = pickle.load(dbfile)\n",
    "dbfile.close()\n",
    "\n",
    "my_path = root / \"Pickled_files\" / \"Files\"\n",
    "dbfile = open(my_path, 'rb')     \n",
    "files = pickle.load(dbfile)\n",
    "dbfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isnumber(token):  \n",
    "    for char in token:\n",
    "        if not (char >= '0' and char <= '9'):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trie\n",
    "We are handling two types of wildcard queries : trailing and leading. We are using a Prefix and Suffix Trie for the same purpose. Every word is checked for stopword and **isnumber** condition, if its neither, the word is inserted in the Prefix Trie and the reverse of the word is inserted into the Suffix Trie. After the processing both Trie objects are pickled and dumped to a binary file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert(word , root) : \n",
    "    cur = 0\n",
    "    for char in word : \n",
    "        if root[cur].get(char) == None : \n",
    "            root[cur][char] = len(root)\n",
    "            root.append(dict())\n",
    "        cur = root[cur][char]\n",
    "    root[cur][\"end\"] = True\n",
    "    if root[cur].get(\"cnt\") == None : \n",
    "        root[cur][\"cnt\"] = 0\n",
    "    root[cur][\"cnt\"] += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Words from Trie\n",
    "Any Wildcard Query has an attribute called **is_suf** which denotes whether the query was a Trailing Wildcard Query or not. The corresponding Query and the Trie Objects are passed to the **wildcard** function. Using the query we traverse over the Trie and upon its end we call a dfs traversal which collects the entire subtree of the point giving us the set of words for the particular wildcard query. Our Trie has a **cnt** attribute in it which signifies how many times the particular prefix/suffix was inserted and hence the retrieved set of words can easily be ranked in decreasing order of **cnt** to get the best 3 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wildcard(word, root , is_suf) : \n",
    "    ans = list()\n",
    "    cur = 0\n",
    "    for char in word : \n",
    "        if root[cur].get(char) == None : \n",
    "            return ans\n",
    "        cur = root[cur][char]\n",
    "    vis = dict()\n",
    "    def dfs(token , id) : \n",
    "        if vis.get(id) != None : \n",
    "            return\n",
    "        vis[id] = 1\n",
    "        if root[id].get(\"cnt\") != None:\n",
    "            if is_suf : \n",
    "                token = token[::-1]\n",
    "            ans.append((token , root[id][\"cnt\"]))\n",
    "        for labels in root[id].keys() :\n",
    "            if len(labels) > 1 :\n",
    "                continue\n",
    "            new_str = token + labels\n",
    "            dfs(new_str , root[id][labels])\n",
    "    dfs(word , cur)\n",
    "    ans = sorted(ans , key = lambda y : -y[1])\n",
    "    ret_list = list()\n",
    "    for i in range(min(3 , len(ans))) :\n",
    "        ret_list.append(ans[i])\n",
    "    return ret_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prefix = list()\n",
    "Prefix.append(dict())\n",
    "Suffix = list()\n",
    "Suffix.append(dict())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insertion into the Trie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in docs: \n",
    "    sentence = sentence[0]\n",
    "    tokens = nltk.tokenize.word_tokenize(str(sentence))\n",
    "    new_token = list()\n",
    "    for i in tokens:\n",
    "        new_token.append(i.lower())\n",
    "    tokens = new_token\n",
    "    for words in new_token: \n",
    "        if words in stop_words or len(words) <= 2 or isnumber(words): \n",
    "            continue\n",
    "        insert(words , Prefix)\n",
    "        insert(words[::-1] , Suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = root / \"Pickled_files\" / \"Prefix_wildcard\"\n",
    "dbfile = open(my_path, 'wb')\n",
    "pickle.dump(Prefix, dbfile) \n",
    "dbfile.close()\n",
    "\n",
    "my_path = root / \"Pickled_files\" / \"Suffix_wildcard\"\n",
    "dbfile = open(my_path, 'wb')\n",
    "pickle.dump(Suffix, dbfile) \n",
    "dbfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = root / \"Pickled_files\" / \"Prefix_wildcard\"\n",
    "dbfile = open(my_path, 'rb')     \n",
    "Prefix = pickle.load(dbfile)\n",
    "dbfile.close()\n",
    "\n",
    "my_path = root / \"Pickled_files\" / \"Suffix_wildcard\"\n",
    "dbfile = open(my_path, 'rb')     \n",
    "Suffix = pickle.load(dbfile)\n",
    "dbfile.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the retrieved set of words from Trie, we normalize each term using PorterStemming and retrieve the corresponding posting list from the inverted index table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(word , type) : \n",
    "    ans = set()\n",
    "    if type : \n",
    "        word_list = wildcard(word , Suffix , True)\n",
    "    else :\n",
    "        word_list = wildcard(word , Prefix , False)\n",
    "    for words in word_list :\n",
    "        normalized_word = stemmer.stem(words[0])\n",
    "        if inverted_idx.get(normalized_word) != None : \n",
    "            for i in range(min(len(inverted_idx[normalized_word]), 2)):\n",
    "                ans.add((docs[inverted_idx[normalized_word][i][0]][0], files[inverted_idx[normalized_word][i][1]]))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file(path) : \n",
    "    ans = \"\"\n",
    "    j = len(path) - 1\n",
    "    while j >= 0 and path[j] != '\\\\' :\n",
    "        ans += path[j]\n",
    "        j -= 1\n",
    "    return ans[::-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wildcard Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)  Property-Owner-Policy-Wording.docx\n",
      "specified illnesses contingencies any occurrence of a specified illness at the premises , except where the premises is a private dwelling any discovery of an organism at the premises likely to result in the occurrence of a specified illness , except where the premises is a private dwelling any occurrence of legionellosis at the premises d the discovery of vermin or pests at the premises e any accident causing defects in the drains or other sanitary arrangements at the premises which causes restrictions on the use of the premises on the order or advice of the competent local authority . \n",
      "-----------------------------------\n",
      "2)  1215E.2.docx\n",
      "illegal use we wo n't pay for loss or damage caused in an incident : if you are unable to maintain proper control of the automobile because you are driving or operating the automobile while under the influence of intoxicating substances ; if you are convicted of one of the following offences under the criminal code of canada relating to the operation , care or control of the automobile , or committed by means of an automobile , or any similar offence under any law in canada or the united states : causing bodily harm by criminal negligence dangerous operation of motor vehicles failure to stop at the scene of an accident operation of motor vehicle when impaired or with more than 80 mg of alcohol in the blood refusal to comply with demand for breath sample causing bodily harm during operation of vehicle while impaired or over 80 mg of alcohol in the blood , or operating a motor vehicle while disqualified from doing so ; if you use or permit the automobile to be used in a race or speed test , or for illegal activity ; if you drive the automobile while not authorized by law ; and if another person , with your permission , drives or operates the automobile under any of these conditions . \n",
      "-----------------------------------\n",
      "3)  complete-property-owner-policy-wording-policies-incepting-or-renewing-from-010418-acom686-11.docx\n",
      "specified illnesses contingencies any occurrence of a specified illness at the premises , except where the premises is a private dwelling any discovery of an organism at the premises likely to result in the occurrence of a specified illness , except where the premises is a private dwelling any occurrence of legionellosis at the premises the discovery of vermin or pests at the premises any accident causing defects in the drains or other sanitary arrangements at the premises which causes restrictions on the use of the premises on the order or advice of the competent local authority . \n",
      "-----------------------------------\n",
      "4)  BRIT-PO-Policy-Wording-May-2016-1.docx\n",
      "any punitive or exemplary damages , compensations , fines or any penalties of whatsoever nature which the insured is ordered to pay by a forum , authority or body of competent jurisdiction ; in respect of coverage clause 1 eviction of squatters only : - a legal expenses incurred in relation to any dispute where the cause of action involves the insured â€™ s legitimate tenant ; b any claim resulting from the occupation of the insured premises or part thereof by squatters prior to the inception of this policy ; c any action consciously taken by the insured that hinders the insurer or appointed representative or adversely affects the course of the legal proceedings initiated for the eviction of squatters ; in respect of coverage clause 5 criminal proceedings only , arising out of any criminal proceedings or allegations in respect of : the ownership , possession of or use of any vehicle ; or any investigation by hmrc or the department for work and pensions ; or assault , violence , fraud , conspiracy to defraud , dishonesty or malicious falsehood ; or the manufacture , dealing in or use of alcohol , illegal drugs or indecent or obscene materials ; or any illegal immigration ; or any money laundering offence under part 7 of the proceeds of crime act 2002 ; or bribery and corruption ; contravention of sanctions . \n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "results = query(\"ill\" , False)\n",
    "cnt = 0\n",
    "for i in results : \n",
    "    print(str(cnt + 1) + \") \" , extract_file(i[1]))\n",
    "    cnt += 1\n",
    "    print(i[0])\n",
    "    print(\"-----------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
